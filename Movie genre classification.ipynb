{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b485a955",
   "metadata": {},
   "source": [
    "# Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b25fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9783d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and saving data in variables\n",
    "\n",
    "# Load the train dataset\n",
    "train_path = r\"C:\\Users\\excel\\Downloads\\archive (1)\\Genre-Classification-Dataset/train_data.txt\"\n",
    "train_data = pd.read_csv(train_path, sep=\":::\", names=['id','title', 'genre', 'description'], engine=\"python\")\n",
    "#train_data.head()\n",
    "\n",
    "# Load the test dataset\n",
    "test_path = r\"C:\\Users\\excel\\Downloads\\archive (1)\\Genre-Classification-Dataset/test_data.txt\"\n",
    "test_data = pd.read_csv(test_path, sep=\":::\", names=['id', 'title', 'description'], engine=\"python\")\n",
    "#test_data.head()\n",
    "\n",
    "# Load the test solutions\n",
    "test_solutions_path = r\"C:\\Users\\excel\\Downloads\\archive (1)\\Genre-Classification-Dataset/test_data_solution.txt\"\n",
    "test_solutions = pd.read_csv(test_solutions_path, sep=\":::\", names=['id', 'title', 'genre', 'description'], engine=\"python\")\n",
    "#test_solutions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a59211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ntlk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c927f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\excel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing the decription text for faster processing:\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5d03d",
   "metadata": {},
   "source": [
    "# Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827e8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text: remove stopwords, punctuation and lemmatize\n",
    "def clean_txt(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Remove stopwords and words with length less than 3\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    \n",
    "    # Join the lemmatized words back into a string\n",
    "    clean_text = \" \".join(lemmatized_words)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "\n",
    "train_data['clean_Description'] = train_data['description'].apply(clean_txt)\n",
    "test_data['clean_test_Desciption'] = test_data['description'].apply(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13910ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>clean_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "      <td>listening conversation doctor parent 10yearold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "      <td>brother sister past incestuous relationship cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "      <td>bus empty student field trip museum natural hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "      <td>help unemployed father make end meet edith twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "      <td>film title refers unrecovered body ground zero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54209</th>\n",
       "      <td>54210</td>\n",
       "      <td>\"Bonino\" (1953)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>This short-lived NBC live sitcom centered on ...</td>\n",
       "      <td>shortlived nbc live sitcom centered bonino wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210</th>\n",
       "      <td>54211</td>\n",
       "      <td>Dead Girls Don't Cry (????)</td>\n",
       "      <td>horror</td>\n",
       "      <td>The NEXT Generation of EXPLOITATION. The sist...</td>\n",
       "      <td>next generation exploitation sister kapa bay s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54211</th>\n",
       "      <td>54212</td>\n",
       "      <td>Ronald Goedemondt: Ze bestaan echt (2008)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Ze bestaan echt, is a stand-up comedy about g...</td>\n",
       "      <td>bestaan echt standup comedy growing facing fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54212</th>\n",
       "      <td>54213</td>\n",
       "      <td>Make Your Own Bed (1944)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>Walter and Vivian live in the country and hav...</td>\n",
       "      <td>walter vivian live country difficult time keep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54213</th>\n",
       "      <td>54214</td>\n",
       "      <td>Nature's Fury: Storm of the Century (2006)</td>\n",
       "      <td>history</td>\n",
       "      <td>On Labor Day Weekend, 1935, the most intense ...</td>\n",
       "      <td>labor day weekend 1935 intense hurricane ever ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54214 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                         title          genre  \\\n",
       "0          1                 Oscar et la dame rose (2009)          drama    \n",
       "1          2                                 Cupid (1997)       thriller    \n",
       "2          3             Young, Wild and Wonderful (1980)          adult    \n",
       "3          4                        The Secret Sin (1915)          drama    \n",
       "4          5                       The Unrecovered (2007)          drama    \n",
       "...      ...                                           ...            ...   \n",
       "54209  54210                              \"Bonino\" (1953)         comedy    \n",
       "54210  54211                  Dead Girls Don't Cry (????)         horror    \n",
       "54211  54212    Ronald Goedemondt: Ze bestaan echt (2008)    documentary    \n",
       "54212  54213                     Make Your Own Bed (1944)         comedy    \n",
       "54213  54214   Nature's Fury: Storm of the Century (2006)        history    \n",
       "\n",
       "                                             description  \\\n",
       "0       Listening in to a conversation between his do...   \n",
       "1       A brother and sister with a past incestuous r...   \n",
       "2       As the bus empties the students for their fie...   \n",
       "3       To help their unemployed father make ends mee...   \n",
       "4       The film's title refers not only to the un-re...   \n",
       "...                                                  ...   \n",
       "54209   This short-lived NBC live sitcom centered on ...   \n",
       "54210   The NEXT Generation of EXPLOITATION. The sist...   \n",
       "54211   Ze bestaan echt, is a stand-up comedy about g...   \n",
       "54212   Walter and Vivian live in the country and hav...   \n",
       "54213   On Labor Day Weekend, 1935, the most intense ...   \n",
       "\n",
       "                                       clean_Description  \n",
       "0      listening conversation doctor parent 10yearold...  \n",
       "1      brother sister past incestuous relationship cu...  \n",
       "2      bus empty student field trip museum natural hi...  \n",
       "3      help unemployed father make end meet edith twi...  \n",
       "4      film title refers unrecovered body ground zero...  \n",
       "...                                                  ...  \n",
       "54209  shortlived nbc live sitcom centered bonino wor...  \n",
       "54210  next generation exploitation sister kapa bay s...  \n",
       "54211  bestaan echt standup comedy growing facing fea...  \n",
       "54212  walter vivian live country difficult time keep...  \n",
       "54213  labor day weekend 1935 intense hurricane ever ...  \n",
       "\n",
       "[54214 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086bcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization (TF-IDF):\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data['clean_Description'])\n",
    "X_test = vectorizer.transform(test_data['clean_test_Desciption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f6bb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split form the training dataset:\n",
    "X = X_train\n",
    "y = train_data['genre']\n",
    "\n",
    "# we don't need a train test split, since we already have distinguished training data and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e7152",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff36baf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, class_weight='balanced', kernel='linear', probability=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Model\n",
    "svm_model = SVC(kernel='linear', C=1, probability=True, class_weight='balanced')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cab78",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe412a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test data type: id              int64\n",
      "title          object\n",
      "genre          object\n",
      "description    object\n",
      "dtype: object\n",
      "y_pred data type: <class 'numpy.ndarray'>\n",
      "y_test data type: <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_test data type: {test_solutions.dtypes}\")\n",
    "print(f\"y_pred data type: {type(y_pred)}\")\n",
    "\n",
    "y_test = test_solutions['genre']\n",
    "print(f\"y_test data type: {type(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "385cb45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5500\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      action        0.32      0.52      0.40      1314\n",
      "       adult        0.49      0.54      0.51       590\n",
      "   adventure        0.32      0.34      0.33       775\n",
      "   animation        0.34      0.19      0.24       498\n",
      "   biography        0.08      0.01      0.02       264\n",
      "      comedy        0.54      0.58      0.56      7446\n",
      "       crime        0.19      0.22      0.21       505\n",
      " documentary        0.75      0.71      0.73     13096\n",
      "       drama        0.66      0.54      0.59     13612\n",
      "      family        0.24      0.26      0.25       783\n",
      "     fantasy        0.28      0.13      0.18       322\n",
      "   game-show        0.79      0.63      0.70       193\n",
      "     history        0.12      0.04      0.06       243\n",
      "      horror        0.58      0.66      0.62      2204\n",
      "       music        0.41      0.71      0.52       731\n",
      "     musical        0.24      0.17      0.20       276\n",
      "     mystery        0.16      0.06      0.08       318\n",
      "        news        0.50      0.19      0.28       181\n",
      "  reality-tv        0.32      0.43      0.37       883\n",
      "     romance        0.17      0.31      0.22       672\n",
      "      sci-fi        0.41      0.45      0.43       646\n",
      "       short        0.40      0.43      0.42      5072\n",
      "       sport        0.40      0.55      0.47       431\n",
      "   talk-show        0.46      0.39      0.42       391\n",
      "    thriller        0.27      0.35      0.30      1590\n",
      "         war        0.29      0.38      0.33       132\n",
      "     western        0.83      0.85      0.84      1032\n",
      "\n",
      "     accuracy                           0.55     54200\n",
      "    macro avg       0.39      0.39      0.38     54200\n",
      " weighted avg       0.57      0.55      0.55     54200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
